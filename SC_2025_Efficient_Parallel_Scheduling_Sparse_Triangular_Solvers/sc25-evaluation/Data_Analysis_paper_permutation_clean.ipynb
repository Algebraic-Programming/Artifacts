{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python version: 3.11.0\n",
    "# matplotlib==3.10.0\n",
    "# pandas==2.2.3\n",
    "# numpy==2.2.1\n",
    "# scipy==1.15.0\n",
    "# scikit-learn==1.6.1\n",
    "# seaborn==0.13.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_stat_files = {\"./graph_hdagg_metis.txt\", \"./graph_florida_stats.txt\", \"./graph_erdos_renyi_stats.txt\", \"./graph_band_stats.txt\", \"./graph_iChol_stats.txt\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading files into pandas dataframe\n",
    "graph_df = pd.concat( [pd.read_csv(file) for file in graph_stat_files ], ignore_index=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping duplicates\n",
    "graph_df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing index to Graph\n",
    "graph_df = graph_df.set_index(\"Graph\", drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding double precision floating point operations to the dataframe\n",
    "graph_df[\"FLOP_double_precision\"] = 2 * graph_df[\"Edges\"] + graph_df[\"Vertices\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding number of non-zeroes to the dataframe\n",
    "graph_df[\"Number_of_non-zeroes\"] = graph_df[\"Edges\"] + graph_df[\"Vertices\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph filter templates\n",
    "\n",
    "# All graphs\n",
    "all_graphs = set(graph_df.index)\n",
    "\n",
    "# Erdos-Renyi graphs\n",
    "erdos_renyi_graphs = set( [g for g in all_graphs if g[:5] == \"Erdos\" ] )\n",
    "\n",
    "# Random Bandwidth graphs\n",
    "random_band_graphs = set( [g for g in all_graphs if g[:10] == \"RandomBand\" ] )\n",
    "\n",
    "# Florida post Eigen Cholesky graphs\n",
    "cholesky_graphs = set( [g for g in all_graphs if g[-9:] == \"_postChol\" ] )\n",
    "florida_metis_graphs = set( [g for g in all_graphs if g[-6:] == \"_metis\" ] )\n",
    "\n",
    "# Florida graphs\n",
    "florida_graphs = set( [g for g in all_graphs if g not in random_band_graphs and g not in erdos_renyi_graphs and g[:4] != \"inst\"  and g not in florida_metis_graphs and g not in cholesky_graphs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting graph filters for subsequent SpTrSV data analysis\n",
    "graph_subset = all_graphs \n",
    "# graph_subset = erdos_renyi_graphs\n",
    "# graph_subset = random_band_graphs\n",
    "# graph_subset = florida_graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpTrSV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder location\n",
    "folder_location = \"./SpTrSV_Data/plot_22_reorder/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing all files in folder_location\n",
    "data_files = set([file for file in os.listdir(folder_location)])\n",
    "data_files = [file for file in data_files if file[:3] != \"log\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying Datatypes\n",
    "data_type_dic = {\n",
    "    \"Graph\":                            \"object\",\n",
    "    \"Machine\":                          \"object\",\n",
    "    \"Algorithm\":                        \"object\",\n",
    "    \"Permutation\":                      \"object\",\n",
    "    \"SpTrSV_Runtime\":                  \"float64\",\n",
    "    \"Work_Cost\":                         \"int64\",\n",
    "    \"Base_Comm_Cost\":                    \"int64\",\n",
    "    \"Supersteps\":                        \"int64\",\n",
    "    \"_Base_Buffered_Sending\":            \"int64\",\n",
    "    \"Base_CostsTotalCommunication\":    \"float64\",\n",
    "    \"Schedule_Compute_time\":             \"int64\",\n",
    "    \"Processors\":                        \"int64\",\n",
    "    \"BSP_g\":                             \"int64\",\n",
    "    \"BSP_l\":                             \"int64\",\n",
    "    \"Scheduling_Threads\":                \"int64\",\n",
    "}\n",
    "\n",
    "data_default_na_val_dic = {\n",
    "    \"Graph\":                              \"\",\n",
    "    \"Machine\":                            \"\",\n",
    "    \"Algorithm\":                          \"\",\n",
    "    \"Permutation\":                        \"\",\n",
    "    \"SpTrSV_Runtime\":                  \"0.0\",\n",
    "    \"Work_Cost\":                         \"0\",\n",
    "    \"Base_Comm_Cost\":                    \"0\",\n",
    "    \"Supersteps\":                        \"1\",\n",
    "    \"_Base_Buffered_Sending\":            \"0\",\n",
    "    \"Base_CostsTotalCommunication\":    \"0.0\",\n",
    "    \"Schedule_Compute_time\":             \"1\",\n",
    "    \"Processors\":                        \"0\",\n",
    "    \"BSP_g\":                             \"0\",\n",
    "    \"BSP_l\":                             \"0\",\n",
    "    \"Scheduling_Threads\":                \"1\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading files into pandas dataframe\n",
    "SpTrSV_df = pd.concat( [pd.read_csv( folder_location + file) for file in data_files], ignore_index=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Deleting folder structure from 'Graph' column\n",
    "SpTrSV_df[\"Graph\"] = SpTrSV_df[\"Graph\"].str.split(\"/\").str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding BSP parameters to the dataframe\n",
    "SpTrSV_df[[\"Processors\", \"BSP_g\", \"BSP_l\"]] = SpTrSV_df[\"Machine\"].str.split(\"_\", n=2, expand=True).reindex(range(3), axis=1)\n",
    "SpTrSV_df[\"Processors\"] = SpTrSV_df[\"Processors\"].astype(\"object\").str.slice(start=1).astype(\"int64\", errors=\"ignore\")\n",
    "SpTrSV_df[\"BSP_g\"] = SpTrSV_df[\"BSP_g\"].astype(\"object\").str.slice(start=1).astype(\"int64\", errors=\"ignore\")\n",
    "SpTrSV_df[\"BSP_l\"] = SpTrSV_df[\"BSP_l\"].astype(\"object\").str.slice(start=1).astype(\"int64\", errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casting to correct Datatypes\n",
    "for key, val in data_type_dic.items():\n",
    "    SpTrSV_df[key] = SpTrSV_df[key].fillna(data_default_na_val_dic[key]).astype(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute giga double precision floating point operations, denoted by GFP64\n",
    "def compute_GFP64(time, graph, df = graph_df):\n",
    "    flop = df.at[graph ,\"FLOP_double_precision\"]\n",
    "    return (flop / time) / 1000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding giga double precision floating point operations, denoted by GFP64, to the dataframe\n",
    "SpTrSV_df[\"GFP64/s\"] = SpTrSV_df[[\"Graph\", \"SpTrSV_Runtime\"]].apply(lambda x: compute_GFP64(x[\"SpTrSV_Runtime\"], x[\"Graph\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set schedule compute time at least 1ms\n",
    "SpTrSV_df[\"Schedule_Compute_time\"] = SpTrSV_df[\"Schedule_Compute_time\"].replace(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data sorting\n",
    "SpTrSV_df.sort_values([ \"Graph\", \"Algorithm\" ], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters (incl. Algorithm, Processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting algorithm filter\n",
    "alg_filter_set = set(SpTrSV_df[\"Algorithm\"].unique())\n",
    "alg_filter_set = set([\"SMGreedyBspGrowLocalAutoCoresParallel\"])\n",
    "alg_filter_set.add(\"Serial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting processor filter\n",
    "proc_filter = {22}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_filter_set = SpTrSV_df[\"Permutation\"].unique()\n",
    "\n",
    "perm_filter_set = set(['NO_PERMUTE', 'LOOP_PROCESSORS'])\n",
    "SpTrSV_df_filtered = SpTrSV_df[ SpTrSV_df[\"Permutation\"].isin(perm_filter_set) ]\n",
    "#perm_filter_set\n",
    "print(SpTrSV_df_filtered[\"Permutation\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying algorithm filter\n",
    "SpTrSV_df_filtered = SpTrSV_df_filtered[ SpTrSV_df_filtered[\"Algorithm\"].isin(alg_filter_set) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying graph filter\n",
    "SpTrSV_df_filtered = SpTrSV_df_filtered[ SpTrSV_df_filtered[\"Graph\"].isin(graph_subset) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying processor filter\n",
    "SpTrSV_df_filtered = SpTrSV_df_filtered[ SpTrSV_df_filtered[\"Processors\"].isin(proc_filter) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up new pandas dataframe with geometric mean of GFP64 and speed-up over serial execution\n",
    "\n",
    "geom_mean_FLOPS_df = pd.DataFrame(columns=[\"Processors\", \"Graphs\", \"Algorithm\", \"Permutation\",\"GFP64/s\", \"Speedup_over_Serial\", \"Speedup_over_HDagg\" , \"Schedule_Compute_time\", \"Schedule_Compute_time_speedup_over_HDagg\", \"Supersteps_relative_to_Wavefront\", \"Supersteps_relative_to_HDagg\"])\n",
    "\n",
    "for name, group in SpTrSV_df_filtered.groupby([\"Processors\", \"Graph\"]):\n",
    "    serial_flops = np.exp( np.log(group[ group[\"Algorithm\"] == \"Serial\" ][\"GFP64/s\"]).mean() )\n",
    "    HDagg_flops = np.exp( np.log(group[ group[\"Algorithm\"] == \"HDagg_original\" ][\"GFP64/s\"]).mean() )\n",
    "    HDagg_schedule_compute_time = group[ group[\"Algorithm\"] == \"HDagg_original\" ][\"Schedule_Compute_time\"].mean()\n",
    "    HDagg_supersteps = group[ group[\"Algorithm\"] == \"HDagg_original\" ][\"Supersteps\"].mean()\n",
    "  \n",
    "    for alg, alg_group in group.groupby([\"Algorithm\", \"Permutation\"]):\n",
    "        flops = np.exp( np.log(alg_group[\"GFP64/s\"]).mean() )\n",
    "        alg_schedule_compute_time = alg_group[\"Schedule_Compute_time\"].mean()\n",
    "        alg_supersteps = alg_group[\"Supersteps\"].mean()\n",
    "        wavefront_supersteps = graph_df.at[name[1], \"Longest_Path\"]\n",
    "        temp_df = pd.DataFrame( [[name[0], name[1], alg[0], alg[1], flops, flops/serial_flops, flops/HDagg_flops, alg_schedule_compute_time, HDagg_schedule_compute_time/alg_schedule_compute_time, alg_supersteps/wavefront_supersteps, alg_supersteps/HDagg_supersteps]], columns=[\"Processors\", \"Graphs\", \"Algorithm\", \"Permutation\", \"GFP64\", \"Speedup_over_Serial\", \"Speedup_over_HDagg\",\"Schedule_Compute_time\", \"Schedule_Compute_time_speedup_over_HDagg\", \"Supersteps_relative_to_Wavefront\", \"Supersteps_relative_to_HDagg\"] )\n",
    "        geom_mean_FLOPS_df = pd.concat([geom_mean_FLOPS_df, temp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding logarithm of speed-up over serial and HDagg\n",
    "geom_mean_FLOPS_df[\"Log2_speedup_over_Serial\"] = np.log2( geom_mean_FLOPS_df[\"Speedup_over_Serial\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GFP64/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Log speed-ups over Serial\n",
    "geom_mean_FLOPS_df[[\"Processors\", \"Algorithm\", \"Permutation\",\"Log2_speedup_over_Serial\"]].groupby([\"Processors\",\"Algorithm\", \"Permutation\"]).mean()\n",
    "\n",
    "florida_FLOPS = geom_mean_FLOPS_df[geom_mean_FLOPS_df[\"Graphs\"].isin(florida_graphs)]\n",
    "florida_agg = florida_FLOPS[[\"Processors\", \"Algorithm\",\"Permutation\",\"Log2_speedup_over_Serial\"]].groupby([\"Processors\",\"Algorithm\",\"Permutation\"]).mean()\n",
    "florida_agg[\"Geommean\"] = np.exp2(florida_agg[\"Log2_speedup_over_Serial\"])\n",
    "\n",
    "###########################################################\n",
    "#####  The output of this cell corresponds to Table 7.3\n",
    "###########################################################\n",
    "\n",
    "print(np.around(florida_agg[\"Geommean\"], decimals=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
