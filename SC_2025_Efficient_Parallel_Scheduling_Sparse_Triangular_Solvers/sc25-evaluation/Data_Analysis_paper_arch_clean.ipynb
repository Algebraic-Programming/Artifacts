{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python version: 3.11.0\n",
    "# matplotlib==3.10.0\n",
    "# pandas==2.2.3\n",
    "# numpy==2.2.1\n",
    "# scipy==1.15.0\n",
    "# scikit-learn==1.6.1\n",
    "# seaborn==0.13.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph statistics files\n",
    "graph_stat_files = {\"./graph_hdagg_metis.txt\", \"./graph_florida_stats.txt\", \"./graph_erdos_renyi_stats.txt\", \"./graph_band_stats.txt\", \"./graph_iChol_stats.txt\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading files into pandas dataframe\n",
    "graph_df = pd.concat( [pd.read_csv(file) for file in graph_stat_files ], ignore_index=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping duplicates\n",
    "graph_df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing index to Graph\n",
    "graph_df = graph_df.set_index(\"Graph\", drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding double precision floating point operations to the dataframe\n",
    "graph_df[\"FLOP_double_precision\"] = 2 * graph_df[\"Edges\"] + graph_df[\"Vertices\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding number of non-zeroes to the dataframe\n",
    "graph_df[\"Number_of_non-zeroes\"] = graph_df[\"Edges\"] + graph_df[\"Vertices\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph filter templates\n",
    "\n",
    "# All graphs\n",
    "all_graphs = set(graph_df.index)\n",
    "\n",
    "# SPAA and AI graphs\n",
    "spaa_ai_graphs = set( [g for g in all_graphs if g[:4] == \"inst\" ] )\n",
    "\n",
    "# Erdos-Renyi graphs\n",
    "erdos_renyi_graphs = set( [g for g in all_graphs if g[:5] == \"Erdos\" ] )\n",
    "\n",
    "# Random Bandwidth graphs\n",
    "random_band_graphs = set( [g for g in all_graphs if g[:10] == \"RandomBand\" ] )\n",
    "\n",
    "# Florida graphs\n",
    "florida_graphs = set( [g for g in all_graphs if g[:10] != \"RandomBand\" and g[:5] != \"Erdos\" and g[:4] != \"inst\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting graph filters for subsequent SpTrSV data analysis\n",
    "graph_subset = florida_graphs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpTrSV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder location\n",
    "folder_location_x86 = \"./SpTrSV_Data/plot_22_x86_SC/\"\n",
    "folder_location_ARM = \"./SpTrSV_Data/plot_22_ARM/\"\n",
    "folder_location_epyc = \"./SpTrSV_Data/plot_22_epyc/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing all files in folder_location\n",
    "data_files_x86 = set([file for file in os.listdir(folder_location_x86)])\n",
    "data_files_x86 \n",
    "data_files_x86 = [file for file in data_files_x86 if file[:3] != \"log\"]\n",
    "\n",
    "# Listing all files in folder_location\n",
    "data_files_ARM = set([file for file in os.listdir(folder_location_ARM)])\n",
    "data_files_ARM \n",
    "data_files_ARM = [file for file in data_files_ARM if file[:3] != \"log\"]\n",
    "\n",
    "# Listing all files in folder_location\n",
    "data_files_epyc = set([file for file in os.listdir(folder_location_epyc)])\n",
    "data_files_epyc \n",
    "data_files_epyc = [file for file in data_files_epyc if file[:3] != \"log\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying Datatypes\n",
    "data_type_dic = {\n",
    "    \"Graph\":                            \"object\",\n",
    "    \"Machine\":                          \"object\",\n",
    "    \"Algorithm\":                        \"object\",\n",
    "    \"Permutation\":                      \"object\",\n",
    "    \"SpTrSV_Runtime\":                  \"float64\",\n",
    "    \"Work_Cost\":                         \"int64\",\n",
    "    \"Base_Comm_Cost\":                    \"int64\",\n",
    "    \"Supersteps\":                        \"int64\",\n",
    "    \"_Base_Buffered_Sending\":            \"int64\",\n",
    "    \"Base_CostsTotalCommunication\":    \"float64\",\n",
    "    \"Schedule_Compute_time\":             \"int64\",\n",
    "    \"Processors\":                        \"int64\",\n",
    "    \"BSP_g\":                             \"int64\",\n",
    "    \"BSP_l\":                             \"int64\",\n",
    "    \"Architecture\":                     \"object\",\n",
    "}\n",
    "\n",
    "data_default_na_val_dic = {\n",
    "    \"Graph\":                              \"\",\n",
    "    \"Machine\":                            \"\",\n",
    "    \"Algorithm\":                          \"\",\n",
    "    \"Permutation\":                        \"\",\n",
    "    \"SpTrSV_Runtime\":                  \"0.0\",\n",
    "    \"Work_Cost\":                         \"0\",\n",
    "    \"Base_Comm_Cost\":                    \"0\",\n",
    "    \"Supersteps\":                        \"1\",\n",
    "    \"_Base_Buffered_Sending\":            \"0\",\n",
    "    \"Base_CostsTotalCommunication\":    \"0.0\",\n",
    "    \"Schedule_Compute_time\":             \"1\",\n",
    "    \"Processors\":                        \"0\",\n",
    "    \"BSP_g\":                             \"0\",\n",
    "    \"BSP_l\":                             \"0\",\n",
    "    \"Architecture\":                       \"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading files into pandas dataframe\n",
    "SpTrSV_df_x86 = pd.concat( [pd.read_csv( folder_location_x86 + file) for file in data_files_x86], ignore_index=True )\n",
    "SpTrSV_df_x86 = SpTrSV_df_x86.assign(Architecture=\"x86\")\n",
    "\n",
    "SpTrSV_df_ARM = pd.concat( [pd.read_csv( folder_location_ARM + file) for file in data_files_ARM], ignore_index=True )\n",
    "SpTrSV_df_ARM = SpTrSV_df_ARM.assign(Architecture=\"ARM\")\n",
    "\n",
    "SpTrSV_df_epyc = pd.concat( [pd.read_csv( folder_location_epyc + file) for file in data_files_epyc], ignore_index=True )\n",
    "SpTrSV_df_epyc = SpTrSV_df_epyc.assign(Architecture=\"epyc\")\n",
    "\n",
    "SpTrSV_df = pd.concat( [SpTrSV_df_x86, SpTrSV_df_ARM, SpTrSV_df_epyc], ignore_index=True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Deleting folder structure from 'Graph' column\n",
    "SpTrSV_df[\"Graph\"] = SpTrSV_df[\"Graph\"].str.split(\"/\").str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding BSP parameters to the dataframe\n",
    "SpTrSV_df[[\"Processors\", \"BSP_g\", \"BSP_l\"]] = SpTrSV_df[\"Machine\"].str.split(\"_\", n=2, expand=True).reindex(range(3), axis=1)\n",
    "SpTrSV_df[\"Processors\"] = SpTrSV_df[\"Processors\"].astype(\"object\").str.slice(start=1).astype(\"int64\", errors=\"ignore\")\n",
    "SpTrSV_df[\"BSP_g\"] = SpTrSV_df[\"BSP_g\"].astype(\"object\").str.slice(start=1).astype(\"int64\", errors=\"ignore\")\n",
    "SpTrSV_df[\"BSP_l\"] = SpTrSV_df[\"BSP_l\"].astype(\"object\").str.slice(start=1).astype(\"int64\", errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casting to correct Datatypes\n",
    "for key, val in data_type_dic.items():\n",
    "    SpTrSV_df[key] = SpTrSV_df[key].fillna(data_default_na_val_dic[key]).astype(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute giga double precision floating point operations, denoted by GFP64\n",
    "def compute_GFP64(time, graph, df = graph_df):\n",
    "    flop = df.at[graph ,\"FLOP_double_precision\"]\n",
    "    return (flop / time) / 1000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding giga double precision floating point operations, denoted by GFP64, to the dataframe\n",
    "SpTrSV_df[\"GFP64/s\"] = SpTrSV_df[[\"Graph\", \"SpTrSV_Runtime\"]].apply(lambda x: compute_GFP64(x[\"SpTrSV_Runtime\"], x[\"Graph\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set schedule compute time at least 1ms\n",
    "SpTrSV_df[\"Schedule_Compute_time\"] = SpTrSV_df[\"Schedule_Compute_time\"].replace(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data sorting\n",
    "SpTrSV_df.sort_values([ \"Graph\", \"Algorithm\" ], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters (incl. Algorithm, Processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting algorithm filter\n",
    "alg_filter_set = set(SpTrSV_df[\"Algorithm\"].unique())\n",
    "alg_filter_set = set([\"HDAGG_BIN\", \"SpMP\", \"SMGreedyBspGrowLocalAutoCoresParallel\"])\n",
    "                   \n",
    "\n",
    "# Must alway contain Serial and HD_original\n",
    "alg_filter_set.add(\"Serial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting processor filter\n",
    "proc_filter = SpTrSV_df[\"Processors\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying algorithm filter\n",
    "SpTrSV_df_filtered = SpTrSV_df[ SpTrSV_df[\"Algorithm\"].isin(alg_filter_set) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying graph filter\n",
    "SpTrSV_df_filtered = SpTrSV_df_filtered[ SpTrSV_df_filtered[\"Graph\"].isin(graph_subset) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying processor filter\n",
    "SpTrSV_df_filtered = SpTrSV_df_filtered[ SpTrSV_df_filtered[\"Processors\"].isin(proc_filter) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up new pandas dataframe with geometric mean of GFP64 and speed-up over serial execution\n",
    "geom_mean_FLOPS_df = pd.DataFrame(columns=[\"Processors\", \"Graphs\", \"Architecture\", \"Algorithm\", \"GFP64/s\", \"Speedup_over_Serial\"])\n",
    "for name, group in SpTrSV_df_filtered.groupby([\"Processors\", \"Graph\", \"Architecture\"]):\n",
    "    serial_flops = np.exp( np.log(group[ group[\"Algorithm\"] == \"Serial\" ][\"GFP64/s\"]).mean() )\n",
    "    \n",
    "    for alg, alg_group in group.groupby(\"Algorithm\"):\n",
    "        flops = np.exp( np.log(alg_group[\"GFP64/s\"]).mean() )\n",
    "        alg_schedule_compute_time = alg_group[\"Schedule_Compute_time\"].mean()\n",
    "        alg_supersteps = alg_group[\"Supersteps\"].mean()\n",
    "        temp_df = pd.DataFrame( [[name[0], name[1], name[2], alg, flops, flops/serial_flops]], columns=[\"Processors\", \"Graphs\", \"Architecture\", \"Algorithm\", \"GFP64\", \"Speedup_over_Serial\", ] )\n",
    "        geom_mean_FLOPS_df = pd.concat([geom_mean_FLOPS_df, temp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding logarithm of speed-up over serial and HDagg\n",
    "geom_mean_FLOPS_df[\"Log2_speedup_over_Serial\"] = np.log2( geom_mean_FLOPS_df[\"Speedup_over_Serial\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GFP64/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Log speed-ups over Serial\n",
    "###########################################################\n",
    "#####  The output of this cell corresponds to Table 7.4\n",
    "###########################################################\n",
    "florida_agg = geom_mean_FLOPS_df[[\"Processors\", \"Algorithm\",\"Architecture\", \"Log2_speedup_over_Serial\"]].groupby([\"Processors\",\"Architecture\",\"Algorithm\",]).mean()\n",
    "florida_agg[\"Geommean\"] = np.exp2(florida_agg[\"Log2_speedup_over_Serial\"])\n",
    "florida_agg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
