{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python version: 3.11.0\n",
    "# matplotlib==3.10.0\n",
    "# pandas==2.2.3\n",
    "# numpy==2.2.1\n",
    "# scipy==1.15.0\n",
    "# scikit-learn==1.6.1\n",
    "# seaborn==0.13.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph statistics files\n",
    "graph_stat_files = {\"./graph_florida_stats.txt\", \"./graph_erdos_renyi_stats.txt\", \"./graph_band_stats.txt\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading files into pandas dataframe\n",
    "graph_df = pd.concat( [pd.read_csv(file) for file in graph_stat_files ], ignore_index=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping duplicates\n",
    "graph_df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing index to Graph\n",
    "graph_df = graph_df.set_index(\"Graph\", drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding double precision floating point operations to the dataframe\n",
    "graph_df[\"FLOP_double_precision\"] = 2 * graph_df[\"Edges\"] + graph_df[\"Vertices\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding number of non-zeroes to the dataframe\n",
    "graph_df[\"Number_of_non-zeroes\"] = graph_df[\"Edges\"] + graph_df[\"Vertices\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph filter templates\n",
    "\n",
    "# All graphs\n",
    "all_graphs = set(graph_df.index)\n",
    "\n",
    "# Erdos-Renyi graphs\n",
    "erdos_renyi_graphs = set( [g for g in all_graphs if g[:5] == \"Erdos\" ] )\n",
    "\n",
    "# Random Bandwidth graphs\n",
    "random_band_graphs = set( [g for g in all_graphs if g[:10] == \"RandomBand\" ] )\n",
    "\n",
    "# Florida graphs\n",
    "florida_graphs = set( [g for g in all_graphs if g[:10] != \"RandomBand\" and g[:5] != \"Erdos\" and g[:4] != \"inst\" ])\n",
    "\n",
    "# Sufficient parallelism\n",
    "sufficient_parallelism_graphs = set(graph_df[ graph_df['Average_Wavefront_Size'] >= 44 ].index)\n",
    "\n",
    "parallelism_graphs_less_than_150 = set(graph_df[ graph_df['Average_Wavefront_Size'] < 128 ].index)\n",
    "parallelism_graphs_150 = set(graph_df[ graph_df['Average_Wavefront_Size'] >= 128 ].index)\n",
    "parallelism_graphs_1000 = set(graph_df[ graph_df['Average_Wavefront_Size'] >= 400 ].index)\n",
    "parallelism_graphs_less_than_1000 = set(graph_df[ graph_df['Average_Wavefront_Size'] < 400 ].index)\n",
    "parallelism_graphs_50000 = set(graph_df[ graph_df['Average_Wavefront_Size'] >= 50000 ].index)\n",
    "parallelism_graphs_less_than_50000 = set(graph_df[ graph_df['Average_Wavefront_Size'] < 50000 ].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting graph filters for subsequent SpTrSV data analysis\n",
    "graph_subset = florida_graphs.intersection(sufficient_parallelism_graphs)\n",
    "print(len(graph_subset))\n",
    "\n",
    "graph_set_p1 = graph_subset.intersection(parallelism_graphs_less_than_150)\n",
    "graph_set_p2 = graph_subset.intersection(parallelism_graphs_150).intersection(parallelism_graphs_less_than_50000)\n",
    "graph_set_p3 = graph_subset.intersection(parallelism_graphs_50000)\n",
    "len(graph_set_p1), len(graph_set_p2), len(graph_set_p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpTrSV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder location\n",
    "folder_location = \"./SpTrSV_Data/plot_epyc/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing all files in folder_location\n",
    "data_files = set([file for file in os.listdir(folder_location)])\n",
    "data_files \n",
    "data_files = [file for file in data_files if file[:3] != \"log\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying Datatypes\n",
    "data_type_dic = {\n",
    "    \"Graph\":                            \"object\",\n",
    "    \"Machine\":                          \"object\",\n",
    "    \"Algorithm\":                        \"object\",\n",
    "    \"Permutation\":                      \"object\",\n",
    "    \"SpTrSV_Runtime\":                  \"float64\",\n",
    "    \"Work_Cost\":                         \"int64\",\n",
    "    \"Base_Comm_Cost\":                    \"int64\",\n",
    "    \"Supersteps\":                        \"int64\",\n",
    "    \"_Base_Buffered_Sending\":            \"int64\",\n",
    "    \"Base_CostsTotalCommunication\":    \"float64\",\n",
    "    \"Schedule_Compute_time\":             \"int64\",\n",
    "    \"Processors\":                        \"int64\",\n",
    "    \"BSP_g\":                             \"int64\",\n",
    "    \"BSP_l\":                             \"int64\",\n",
    "}\n",
    "\n",
    "data_default_na_val_dic = {\n",
    "    \"Graph\":                              \"\",\n",
    "    \"Machine\":                            \"\",\n",
    "    \"Algorithm\":                          \"\",\n",
    "    \"Permutation\":                        \"\",\n",
    "    \"SpTrSV_Runtime\":                  \"0.0\",\n",
    "    \"Work_Cost\":                         \"0\",\n",
    "    \"Base_Comm_Cost\":                    \"0\",\n",
    "    \"Supersteps\":                        \"1\",\n",
    "    \"_Base_Buffered_Sending\":            \"0\",\n",
    "    \"Base_CostsTotalCommunication\":    \"0.0\",\n",
    "    \"Schedule_Compute_time\":             \"1\",\n",
    "    \"Processors\":                        \"0\",\n",
    "    \"BSP_g\":                             \"0\",\n",
    "    \"BSP_l\":                             \"0\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading files into pandas dataframe\n",
    "SpTrSV_df = pd.concat( [pd.read_csv( folder_location + file) for file in data_files], ignore_index=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Deleting folder structure from 'Graph' column\n",
    "SpTrSV_df[\"Graph\"] = SpTrSV_df[\"Graph\"].str.split(\"/\").str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding BSP parameters to the dataframe\n",
    "SpTrSV_df[[\"Processors\", \"BSP_g\", \"BSP_l\"]] = SpTrSV_df[\"Machine\"].str.split(\"_\", n=2, expand=True).reindex(range(3), axis=1)\n",
    "SpTrSV_df[\"Processors\"] = SpTrSV_df[\"Processors\"].astype(\"object\").str.slice(start=1).astype(\"int64\", errors=\"ignore\")\n",
    "SpTrSV_df[\"BSP_g\"] = SpTrSV_df[\"BSP_g\"].astype(\"object\").str.slice(start=1).astype(\"int64\", errors=\"ignore\")\n",
    "SpTrSV_df[\"BSP_l\"] = SpTrSV_df[\"BSP_l\"].astype(\"object\").str.slice(start=1).astype(\"int64\", errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casting to correct Datatypes\n",
    "for key, val in data_type_dic.items():\n",
    "    SpTrSV_df[key] = SpTrSV_df[key].fillna(data_default_na_val_dic[key]).astype(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute giga double precision floating point operations, denoted by GFP64\n",
    "def compute_GFP64(time, graph, df = graph_df):\n",
    "    flop = df.at[graph ,\"FLOP_double_precision\"]\n",
    "    return (flop / time) / 1000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding giga double precision floating point operations, denoted by GFP64, to the dataframe\n",
    "SpTrSV_df[\"GFP64/s\"] = SpTrSV_df[[\"Graph\", \"SpTrSV_Runtime\"]].apply(lambda x: compute_GFP64(x[\"SpTrSV_Runtime\"], x[\"Graph\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set schedule compute time at least 1ms\n",
    "SpTrSV_df[\"Schedule_Compute_time\"] = SpTrSV_df[\"Schedule_Compute_time\"].replace(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data sorting\n",
    "SpTrSV_df.sort_values([ \"Graph\", \"Algorithm\" ], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data sample\n",
    "SpTrSV_df = SpTrSV_df.assign(Average_Wavefront_Size = SpTrSV_df[\"Graph\"].map(graph_df[\"Average_Wavefront_Size\"]))\n",
    "SpTrSV_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters (incl. Algorithm, Processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting algorithm filter\n",
    "alg_filter_set = set(SpTrSV_df[\"Algorithm\"].unique())\n",
    "alg_filter_set = set([\"HDAGG_BIN\", \"SpMP\", \"SMGreedyBspGrowLocalAutoCoresParallel\"])\n",
    "\n",
    "# Must alway contain Serial and HD_original\n",
    "alg_filter_set.add(\"Serial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting processor filter\n",
    "proc_filter = SpTrSV_df[\"Processors\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_filter_set = SpTrSV_df[\"Permutation\"].unique()\n",
    "#print(perm_filter_set)\n",
    "perm_filter_set = set(['NO_PERMUTE', 'LOOP_PROCESSORS'])\n",
    "SpTrSV_df_filtered = SpTrSV_df[ SpTrSV_df[\"Permutation\"].isin(perm_filter_set) ]\n",
    "print(SpTrSV_df_filtered[\"Permutation\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying algorithm filter\n",
    "SpTrSV_df_filtered = SpTrSV_df_filtered[ SpTrSV_df_filtered[\"Algorithm\"].isin(alg_filter_set) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying graph filter\n",
    "SpTrSV_df_filtered = SpTrSV_df_filtered[ SpTrSV_df_filtered[\"Graph\"].isin(graph_subset) ]\n",
    "\n",
    "print(\n",
    "len(SpTrSV_df_filtered[ SpTrSV_df_filtered[\"Graph\"].isin(graph_set_p1)][\"Graph\"].unique())\n",
    ",\n",
    "len(SpTrSV_df_filtered[ SpTrSV_df_filtered[\"Graph\"].isin(graph_set_p2)][\"Graph\"].unique())\n",
    ",\n",
    "len(SpTrSV_df_filtered[ SpTrSV_df_filtered[\"Graph\"].isin(graph_set_p3)][\"Graph\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying processor filter\n",
    "SpTrSV_df_filtered = SpTrSV_df_filtered[ SpTrSV_df_filtered[\"Processors\"].isin(proc_filter) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying remaining graphs in the dataframe\n",
    "graphs_in_data_set = SpTrSV_df_filtered[\"Graph\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up new pandas dataframe with geometric mean of GFP64 and speed-up over serial execution\n",
    "\n",
    "geom_mean_FLOPS_df = pd.DataFrame(columns=[\"Processors\", \"Graphs\", \"Algorithm\", \"GFP64/s\", \"Speedup_over_Serial\"])\n",
    "\n",
    "for name, group in SpTrSV_df_filtered.groupby([\"Processors\", \"Graph\"]):\n",
    "    serial_flops = np.exp( np.log(group[ group[\"Algorithm\"] == \"Serial\" ][\"GFP64/s\"]).mean() )\n",
    "  \n",
    "    for alg, alg_group in group.groupby([\"Algorithm\"]):\n",
    "        flops = np.exp( np.log(alg_group[\"GFP64/s\"]).mean() )\n",
    "        alg_schedule_compute_time = alg_group[\"Schedule_Compute_time\"].mean()\n",
    "        alg_supersteps = alg_group[\"Supersteps\"].mean()\n",
    "        wavefront_supersteps = graph_df.at[name[1], \"Longest_Path\"]\n",
    "        temp_df = pd.DataFrame( [[name[0], name[1], alg[0], flops, flops/serial_flops]], columns=[\"Processors\", \"Graphs\", \"Algorithm\", \"GFP64\", \"Speedup_over_Serial\"] )\n",
    "        geom_mean_FLOPS_df = pd.concat([geom_mean_FLOPS_df, temp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding logarithm of speed-up over serial and HDagg\n",
    "geom_mean_FLOPS_df[\"Log2_speedup_over_Serial\"] = np.log2( geom_mean_FLOPS_df[\"Speedup_over_Serial\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data sample\n",
    "geom_mean_FLOPS_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GFP64/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Log speed-ups over Serial\n",
    "\n",
    "###########################################################\n",
    "#####  The output of this cell corresponds to Table 7.5\n",
    "###########################################################\n",
    "\n",
    "florida_agg = geom_mean_FLOPS_df[[\"Processors\", \"Algorithm\",\"Log2_speedup_over_Serial\"]].groupby([\"Processors\",\"Algorithm\"]).mean()\n",
    "florida_agg[\"Geommean\"] = np.exp2(florida_agg[\"Log2_speedup_over_Serial\"])\n",
    "\n",
    "for name, group in florida_agg.groupby([\"Algorithm\"]):\n",
    "    print(name)\n",
    "    print(np.around(group[\"Geommean\"], decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "#####  The output of this cell corresponds to Figure 7.2\n",
    "###########################################################\n",
    "\n",
    "\n",
    "x = geom_mean_FLOPS_df[geom_mean_FLOPS_df[\"Algorithm\"].isin([\"SMGreedyBspGrowLocalAutoCoresParallel\"])]\n",
    "\n",
    "x = x.assign(graph_group=1)\n",
    "x.loc[x[\"Graphs\"].isin(graph_set_p2), \"graph_group\"] = 2\n",
    "x.loc[x[\"Graphs\"].isin(graph_set_p3), \"graph_group\"] = 3\n",
    "\n",
    "plt.figure(figsize=(7,3))\n",
    "\n",
    "\n",
    "ax = sns.lineplot(data=x, palette=sns.color_palette(\"husl\", 3), x=\"Processors\",  y=\"Speedup_over_Serial\", errorbar=None, hue=\"graph_group\", style=\"graph_group\")\n",
    "\n",
    "plt.xlabel(\"\", fontsize=0, labelpad=10)\n",
    "plt.legend(title='Avg. wavefront size', labels=['44-127', '128-1200' , \">50000\"] , loc=\"upper left\", fontsize=12, title_fontsize=12)    \n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "    \n",
    "plt.ylabel(\"Speed-up over Serial\", fontsize=14)\n",
    "plt.savefig(\"scaling_plot_dc.eps\", bbox_inches=\"tight\", transparent=True)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
