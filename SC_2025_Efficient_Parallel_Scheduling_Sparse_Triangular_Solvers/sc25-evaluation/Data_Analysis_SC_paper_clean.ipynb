{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python version: 3.11.0\n",
    "# matplotlib==3.10.0\n",
    "# pandas==2.2.3\n",
    "# numpy==2.2.1\n",
    "# scipy==1.15.0\n",
    "# scikit-learn==1.6.1\n",
    "# seaborn==0.13.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph statistics files\n",
    "graph_stat_files = {\"./graph_hdagg_metis.txt\", \"./graph_florida_stats.txt\", \"./graph_erdos_renyi_stats.txt\", \"./graph_band_stats.txt\", \"./graph_iChol_stats.txt\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading files into pandas dataframe\n",
    "graph_df = pd.concat( [pd.read_csv(file) for file in graph_stat_files ], ignore_index=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping duplicates\n",
    "graph_df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing index to Graph\n",
    "graph_df = graph_df.set_index(\"Graph\", drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding double precision floating point operations to the dataframe\n",
    "graph_df[\"FLOP_double_precision\"] = 2 * graph_df[\"Edges\"] + graph_df[\"Vertices\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding number of non-zeroes to the dataframe\n",
    "graph_df[\"Number_of_non-zeroes\"] = graph_df[\"Edges\"] + graph_df[\"Vertices\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph filter templates\n",
    "\n",
    "# All graphs\n",
    "all_graphs = set(graph_df.index)\n",
    "\n",
    "# Erdos-Renyi graphs\n",
    "erdos_renyi_graphs = set( [g for g in all_graphs if g[:5] == \"Erdos\" ] )\n",
    "\n",
    "# Random Bandwidth graphs\n",
    "random_band_graphs = set( [g for g in all_graphs if g[:10] == \"RandomBand\" ] )\n",
    "\n",
    "# Florida METIS and post Eigen Cholesky graphs\n",
    "cholesky_graphs = set( [g for g in all_graphs if g[-9:] == \"_postChol\" ] )\n",
    "florida_metis_graphs = set( [g for g in all_graphs if g[-6:] == \"_metis\" ] )\n",
    "\n",
    "# Florida (SuiteSparse) graphs\n",
    "florida_graphs = set( [g for g in all_graphs if g not in random_band_graphs and g not in erdos_renyi_graphs and g[:4] != \"inst\"  and g not in florida_metis_graphs and g not in cholesky_graphs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting graph filters for subsequent SpTrSV data analysis\n",
    "graph_subset = all_graphs \n",
    "# graph_subset = erdos_renyi_graphs\n",
    "# graph_subset = random_band_graphs\n",
    "# graph_subset = cholesky_graphs\n",
    "# graph_subset = florida_graphs\n",
    "# graph_subset = florida_metis_graphs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpTrSV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder location\n",
    "folder_location = \"./SpTrSV_Data/SC_paper/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All files in folder_location\n",
    "data_files = set([file for file in os.listdir(folder_location)])\n",
    "data_files = [file for file in data_files if file[:3] != \"log\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying Datatypes\n",
    "data_type_dic = {\n",
    "    \"Graph\":                            \"object\",\n",
    "    \"Machine\":                          \"object\",\n",
    "    \"Algorithm\":                        \"object\",\n",
    "    \"Permutation\":                      \"object\",\n",
    "    \"SpTrSV_Runtime\":                  \"float64\",\n",
    "    \"Work_Cost\":                         \"int64\",\n",
    "    \"Base_Comm_Cost\":                    \"int64\",\n",
    "    \"Supersteps\":                        \"int64\",\n",
    "    \"_Base_Buffered_Sending\":            \"int64\",\n",
    "    \"Base_CostsTotalCommunication\":    \"float64\",\n",
    "    \"Schedule_Compute_time\":             \"int64\",\n",
    "    \"Processors\":                        \"int64\",\n",
    "    \"BSP_g\":                             \"int64\",\n",
    "    \"BSP_l\":                             \"int64\",\n",
    "    \"Scheduling_Threads\":                \"int64\",\n",
    "}\n",
    "\n",
    "data_default_na_val_dic = {\n",
    "    \"Graph\":                              \"\",\n",
    "    \"Machine\":                            \"\",\n",
    "    \"Algorithm\":                          \"\",\n",
    "    \"Permutation\":                        \"\",\n",
    "    \"SpTrSV_Runtime\":                  \"0.0\",\n",
    "    \"Work_Cost\":                         \"0\",\n",
    "    \"Base_Comm_Cost\":                    \"0\",\n",
    "    \"Supersteps\":                        \"1\",\n",
    "    \"_Base_Buffered_Sending\":            \"0\",\n",
    "    \"Base_CostsTotalCommunication\":    \"0.0\",\n",
    "    \"Schedule_Compute_time\":             \"1\",\n",
    "    \"Processors\":                        \"0\",\n",
    "    \"BSP_g\":                             \"0\",\n",
    "    \"BSP_l\":                             \"0\",\n",
    "    \"Scheduling_Threads\":                \"1\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading files into pandas dataframe\n",
    "SpTrSV_df = pd.concat( [pd.read_csv( folder_location + file) for file in data_files], ignore_index=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Deleting folder structure from 'Graph' column\n",
    "SpTrSV_df[\"Graph\"] = SpTrSV_df[\"Graph\"].str.split(\"/\").str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding BSP parameters to the dataframe\n",
    "SpTrSV_df[[\"Processors\", \"BSP_g\", \"BSP_l\"]] = SpTrSV_df[\"Machine\"].str.split(\"_\", n=2, expand=True).reindex(range(3), axis=1)\n",
    "SpTrSV_df[\"Processors\"] = SpTrSV_df[\"Processors\"].astype(\"object\").str.slice(start=1).astype(\"int64\", errors=\"ignore\")\n",
    "SpTrSV_df[\"BSP_g\"] = SpTrSV_df[\"BSP_g\"].astype(\"object\").str.slice(start=1).astype(\"int64\", errors=\"ignore\")\n",
    "SpTrSV_df[\"BSP_l\"] = SpTrSV_df[\"BSP_l\"].astype(\"object\").str.slice(start=1).astype(\"int64\", errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casting to correct Datatypes\n",
    "for key, val in data_type_dic.items():\n",
    "    SpTrSV_df[key] = SpTrSV_df[key].fillna(data_default_na_val_dic[key]).astype(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute giga double precision floating point operations, denoted by GFP64\n",
    "def compute_GFP64(time, graph, df = graph_df):\n",
    "    flop = df.at[graph ,\"FLOP_double_precision\"]\n",
    "    return (flop / time) / 1000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding giga double precision floating point operations, denoted by GFP64, to the dataframe\n",
    "SpTrSV_df[\"GFP64/s\"] = SpTrSV_df[[\"Graph\", \"SpTrSV_Runtime\"]].apply(lambda x: compute_GFP64(x[\"SpTrSV_Runtime\"], x[\"Graph\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set schedule compute time at least 1ms\n",
    "SpTrSV_df[\"Schedule_Compute_time\"] = SpTrSV_df[\"Schedule_Compute_time\"].replace(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data sorting\n",
    "SpTrSV_df.sort_values([ \"Graph\", \"Algorithm\" ], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters (incl. Algorithm, Processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all algorithms\n",
    "SpTrSV_df[\"Algorithm\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting algorithm filter\n",
    "alg_filter_set = set(SpTrSV_df[\"Algorithm\"].unique())\n",
    "alg_filter_set = set([\"HDAGG_BIN\", \"SpMP\", \"SMGreedyBspGrowLocalAutoCoresParallel\", \"SMFunOriGrowlv2\" ])\n",
    "\n",
    "# Must always contain Serial and HDAGG_BIN\n",
    "alg_filter_set.add(\"Serial\")\n",
    "alg_filter_set.add(\"HDAGG_BIN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting processor filter\n",
    "proc_filter = SpTrSV_df[\"Processors\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scheduling Threads filter\n",
    "sched_thread_filter = {1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying algorithm filter\n",
    "SpTrSV_df_filtered = SpTrSV_df[ SpTrSV_df[\"Algorithm\"].isin(alg_filter_set) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying graph filter\n",
    "SpTrSV_df_filtered = SpTrSV_df_filtered[ SpTrSV_df_filtered[\"Graph\"].isin(graph_subset) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying processor filter\n",
    "SpTrSV_df_filtered = SpTrSV_df_filtered[ SpTrSV_df_filtered[\"Processors\"].isin(proc_filter) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying scheduling filter\n",
    "SpTrSV_df_filtered = SpTrSV_df_filtered[ SpTrSV_df_filtered[\"Scheduling_Threads\"].isin(sched_thread_filter) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up new pandas dataframe with geometric mean of GFP64 and speed-up over serial execution\n",
    "geom_mean_FLOPS_df = pd.DataFrame(columns=[\"Processors\", \"Graphs\", \"Algorithm\", \"GFP64/s\", \"Speedup_over_Serial\", \"Speedup_over_HDagg\", \"Speedup_over_SpMP\" , \"Profitability\", \"Schedule_Compute_time\", \"Schedule_Compute_time_speedup_over_HDagg\", \"Supersteps_relative_to_Wavefront\", \"Supersteps_relative_to_HDagg\", \"super_step_reduction\"])\n",
    "for name, group in SpTrSV_df_filtered.groupby([\"Processors\", \"Graph\"]):\n",
    "    serial_flops = np.exp( np.log(group[ group[\"Algorithm\"] == \"Serial\" ][\"GFP64/s\"]).mean() )\n",
    "    serial_run_time_am = group[group[\"Algorithm\"] == \"Serial\" ][\"SpTrSV_Runtime\"].mean()\n",
    "    SpMP_flops = np.nan\n",
    "    if group[ group[\"Algorithm\"] == \"SpMP\" ][\"GFP64/s\"].count() > 0:\n",
    "        SpMP_flops = np.exp( np.log(group[ group[\"Algorithm\"] == \"SpMP\" ][\"GFP64/s\"]).mean() )\n",
    "    HDagg_flops = np.nan\n",
    "    if group[ group[\"Algorithm\"] == \"HDAGG_BIN\" ][\"GFP64/s\"].count() > 0:\n",
    "        HDagg_flops = np.exp( np.log(group[ group[\"Algorithm\"] == \"HDAGG_BIN\" ][\"GFP64/s\"]).mean() )\n",
    "    HDagg_schedule_compute_time = np.nan\n",
    "    if group[ group[\"Algorithm\"] == \"HDAGG_BIN\" ][\"Schedule_Compute_time\"].count() > 0:\n",
    "        HDagg_schedule_compute_time = group[ group[\"Algorithm\"] == \"HDAGG_BIN\" ][\"Schedule_Compute_time\"].mean()\n",
    "    HDagg_supersteps = np.nan\n",
    "    if group[ group[\"Algorithm\"] == \"HDAGG_BIN\" ][\"Supersteps\"].count() > 0:\n",
    "        HDagg_supersteps = group[ group[\"Algorithm\"] == \"HDAGG_BIN\" ][\"Supersteps\"].mean()\n",
    "    \n",
    "   \n",
    "    for alg, alg_group in group.groupby(\"Algorithm\"):\n",
    "        flops = np.exp( np.log(alg_group[\"GFP64/s\"]).mean())\n",
    "        run_time_am = alg_group[\"SpTrSV_Runtime\"].mean()\n",
    "        alg_schedule_compute_time = alg_group[\"Schedule_Compute_time\"].mean()\n",
    "        alg_supersteps = alg_group[\"Supersteps\"].mean()\n",
    "        wavefront_supersteps = graph_df.at[name[1], \"Longest_Path\"]\n",
    "\n",
    "        profitable = 0\n",
    "        if (alg == \"Serial\"):\n",
    "            profitable = 0\n",
    "        else:\n",
    "            # conversion of alg_schedule_compute_time to s from ms\n",
    "            profitable = (alg_schedule_compute_time / 1000.0) / (serial_run_time_am - run_time_am)\n",
    "            if (profitable < 0.0):\n",
    "                profitable = np.inf\n",
    "            \n",
    "        temp_df = pd.DataFrame([[name[0],      name[1],  alg,         flops,   flops/serial_flops,    flops/HDagg_flops,    flops/SpMP_flops,    profitable,      alg_schedule_compute_time, HDagg_schedule_compute_time/alg_schedule_compute_time, alg_supersteps/wavefront_supersteps, alg_supersteps/HDagg_supersteps, (HDagg_supersteps - alg_supersteps)/HDagg_supersteps ]],\n",
    "                        columns=[\"Processors\", \"Graphs\", \"Algorithm\", \"GFP64/s\", \"Speedup_over_Serial\", \"Speedup_over_HDagg\", \"Speedup_over_SpMP\", \"Profitability\", \"Schedule_Compute_time\",   \"Schedule_Compute_time_speedup_over_HDagg\",            \"Supersteps_relative_to_Wavefront\",  \"Supersteps_relative_to_HDagg\",  \"super_step_reduction\"] )\n",
    "        geom_mean_FLOPS_df = pd.concat([geom_mean_FLOPS_df, temp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding logarithm of speed-up over serial and HDagg\n",
    "geom_mean_FLOPS_df[\"Log2_speedup_over_Serial\"] = np.log2( geom_mean_FLOPS_df[\"Speedup_over_Serial\"] )\n",
    "geom_mean_FLOPS_df[\"Log2_speedup_over_HDagg\"] = np.log2( geom_mean_FLOPS_df[\"Speedup_over_HDagg\"] )\n",
    "geom_mean_FLOPS_df[\"Log2_speedup_over_SpMP\"] = np.log2( geom_mean_FLOPS_df[\"Speedup_over_SpMP\"] )\n",
    "geom_mean_FLOPS_df[\"Log2_supersteps_relative_to_Wavefront\"] = np.log2( geom_mean_FLOPS_df[\"Supersteps_relative_to_Wavefront\"] )\n",
    "geom_mean_FLOPS_df[\"Log2_supersteps_relative_to_HDagg\"] = np.log2( geom_mean_FLOPS_df[\"Supersteps_relative_to_HDagg\"] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding logarithm of schedule compute time over HDagg\n",
    "geom_mean_FLOPS_df[\"Log2_Schedule_Compute_time_speedup_over_HDagg\"] = np.log2( geom_mean_FLOPS_df[\"Schedule_Compute_time_speedup_over_HDagg\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding number of non-zeros\n",
    "geom_mean_FLOPS_df[\"NNZ\"] = geom_mean_FLOPS_df[\"Graphs\"].apply(lambda x: graph_df.at[x,\"Number_of_non-zeroes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GFP64/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Log speed-ups over Serial\n",
    "florida_FLOPS = geom_mean_FLOPS_df[geom_mean_FLOPS_df[\"Graphs\"].isin(florida_graphs)]\n",
    "\n",
    "# SuiteSparse data set - main SpTRSV experiments\n",
    "florida_agg = florida_FLOPS[[\"Processors\", \"Algorithm\",\"Log2_speedup_over_Serial\", \"Log2_speedup_over_HDagg\", \"Log2_speedup_over_SpMP\" , \"Profitability\", \"Schedule_Compute_time\", \"Schedule_Compute_time_speedup_over_HDagg\", \"Supersteps_relative_to_HDagg\", \"Log2_supersteps_relative_to_Wavefront\", \"Log2_supersteps_relative_to_HDagg\"]].groupby([\"Processors\",\"Algorithm\"]).mean()\n",
    "florida_agg[\"Geommean_serial\"] = np.exp2(florida_agg[\"Log2_speedup_over_Serial\"])\n",
    "florida_agg[\"Geommean_hdagg\"] = np.exp2(florida_agg[\"Log2_speedup_over_HDagg\"])\n",
    "florida_agg[\"Geommean_spmp\"] = np.exp2(florida_agg[\"Log2_speedup_over_SpMP\"])\n",
    "florida_agg[\"Geommean_supersteps_relative_to_Wavefront\"] = 1 / np.exp2(florida_agg[\"Log2_supersteps_relative_to_Wavefront\"])\n",
    "florida_agg[\"Geommean_supersteps_relative_to_HDagg\"] = 1 / np.exp2(florida_agg[\"Log2_supersteps_relative_to_HDagg\"])\n",
    "\n",
    "# SuiteSparse data set - amortization threshold\n",
    "florida_agg[\"median_profitability\"] = florida_FLOPS[[\"Processors\", \"Algorithm\",\"Profitability\"]].groupby([\"Processors\",\"Algorithm\"]).median()\n",
    "florida_agg[\"q25\"] = florida_FLOPS[[\"Processors\", \"Algorithm\",\"Profitability\"]].groupby([\"Processors\",\"Algorithm\"]).quantile(0.25)\n",
    "florida_agg[\"q75\"] = florida_FLOPS[[\"Processors\", \"Algorithm\",\"Profitability\"]].groupby([\"Processors\",\"Algorithm\"]).quantile(0.75)\n",
    "\n",
    "\n",
    "# Erdos-Renyi data set - main SpTRSV experiments\n",
    "er_FLOPS = geom_mean_FLOPS_df[geom_mean_FLOPS_df[\"Graphs\"].isin(erdos_renyi_graphs)]\n",
    "er_agg = er_FLOPS[[\"Processors\", \"Algorithm\",\"Log2_speedup_over_Serial\", \"Log2_speedup_over_HDagg\", \"Log2_speedup_over_SpMP\" , \"Profitability\", \"Schedule_Compute_time\", \"Schedule_Compute_time_speedup_over_HDagg\", \"Supersteps_relative_to_HDagg\", \"Log2_supersteps_relative_to_Wavefront\", \"Log2_supersteps_relative_to_HDagg\"]].groupby([\"Processors\",\"Algorithm\"]).mean()\n",
    "er_agg[\"Geommean_serial\"] = np.exp2(er_agg[\"Log2_speedup_over_Serial\"])\n",
    "er_agg[\"Geommean_hdagg\"] = np.exp2(er_agg[\"Log2_speedup_over_HDagg\"])\n",
    "er_agg[\"Geommean_spmp\"] = np.exp2(er_agg[\"Log2_speedup_over_SpMP\"])\n",
    "er_agg[\"Geommean_supersteps_relative_to_Wavefront\"] = 1 / np.exp2(er_agg[\"Log2_supersteps_relative_to_Wavefront\"])\n",
    "er_agg[\"median_profitability\"] = er_FLOPS[[\"Processors\", \"Algorithm\",\"Profitability\"]].groupby([\"Processors\",\"Algorithm\"]).median()\n",
    "er_agg[\"q25\"] = er_FLOPS[[\"Processors\", \"Algorithm\",\"Profitability\"]].groupby([\"Processors\",\"Algorithm\"]).quantile(0.25)\n",
    "er_agg[\"q75\"] = er_FLOPS[[\"Processors\", \"Algorithm\",\"Profitability\"]].groupby([\"Processors\",\"Algorithm\"]).quantile(0.75)\n",
    "\n",
    "# Narrow Bandwidth data set - main SpTRSV experiments\n",
    "rb_FLOPS = geom_mean_FLOPS_df[geom_mean_FLOPS_df[\"Graphs\"].isin(random_band_graphs)]\n",
    "rb_agg = rb_FLOPS[[\"Processors\", \"Algorithm\",\"Log2_speedup_over_Serial\", \"Log2_speedup_over_HDagg\", \"Log2_speedup_over_SpMP\" , \"Profitability\", \"Schedule_Compute_time\", \"Schedule_Compute_time_speedup_over_HDagg\", \"Supersteps_relative_to_HDagg\", \"Log2_supersteps_relative_to_Wavefront\", \"Log2_supersteps_relative_to_HDagg\"]].groupby([\"Processors\",\"Algorithm\"]).mean()\n",
    "rb_agg[\"Geommean_serial\"] = np.exp2(rb_agg[\"Log2_speedup_over_Serial\"])\n",
    "rb_agg[\"Geommean_hdagg\"] = np.exp2(rb_agg[\"Log2_speedup_over_HDagg\"])\n",
    "rb_agg[\"Geommean_spmp\"] = np.exp2(rb_agg[\"Log2_speedup_over_SpMP\"])\n",
    "rb_agg[\"Geommean_supersteps_relative_to_Wavefront\"] = 1 / np.exp2(rb_agg[\"Log2_supersteps_relative_to_Wavefront\"])\n",
    "rb_agg[\"median_profitability\"] = rb_FLOPS[[\"Processors\", \"Algorithm\",\"Profitability\"]].groupby([\"Processors\",\"Algorithm\"]).median()\n",
    "rb_agg[\"q25\"] = rb_FLOPS[[\"Processors\", \"Algorithm\",\"Profitability\"]].groupby([\"Processors\",\"Algorithm\"]).quantile(0.25)\n",
    "rb_agg[\"q75\"] = rb_FLOPS[[\"Processors\", \"Algorithm\",\"Profitability\"]].groupby([\"Processors\",\"Algorithm\"]).quantile(0.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METIS data set - main SpTRSV experiments\n",
    "florida_metis_FLOPS = geom_mean_FLOPS_df[geom_mean_FLOPS_df[\"Graphs\"].isin(florida_metis_graphs)]\n",
    "florida_metis_agg = florida_metis_FLOPS[[\"Processors\", \"Algorithm\",\"Log2_speedup_over_Serial\", \"Log2_speedup_over_HDagg\", \"Log2_speedup_over_SpMP\" , \"Profitability\", \"Schedule_Compute_time\", \"Schedule_Compute_time_speedup_over_HDagg\", \"Supersteps_relative_to_HDagg\", \"Log2_supersteps_relative_to_Wavefront\", \"Log2_supersteps_relative_to_HDagg\"]].groupby([\"Processors\",\"Algorithm\"]).mean()\n",
    "florida_metis_agg[\"Geommean_serial\"] = np.exp2(florida_metis_agg[\"Log2_speedup_over_Serial\"])\n",
    "florida_metis_agg[\"Geommean_hdagg\"] = np.exp2(florida_metis_agg[\"Log2_speedup_over_HDagg\"])\n",
    "florida_metis_agg[\"Geommean_spmp\"] = np.exp2(florida_metis_agg[\"Log2_speedup_over_SpMP\"])\n",
    "florida_metis_agg[\"Geommean_supersteps_relative_to_Wavefront\"] = 1 / np.exp2(florida_metis_agg[\"Log2_supersteps_relative_to_Wavefront\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iChol data set - main SpTRSV experiments\n",
    "florida_pchol_FLOPS = geom_mean_FLOPS_df[geom_mean_FLOPS_df[\"Graphs\"].isin(cholesky_graphs)]\n",
    "florida_pchol_agg = florida_pchol_FLOPS[[\"Processors\", \"Algorithm\",\"Log2_speedup_over_Serial\", \"Log2_speedup_over_HDagg\", \"Log2_speedup_over_SpMP\" , \"Profitability\", \"Schedule_Compute_time\", \"Schedule_Compute_time_speedup_over_HDagg\", \"Supersteps_relative_to_HDagg\", \"Log2_supersteps_relative_to_Wavefront\", \"Log2_supersteps_relative_to_HDagg\"]].groupby([\"Processors\",\"Algorithm\"]).mean()\n",
    "florida_pchol_agg[\"Geommean_serial\"] = np.exp2(florida_pchol_agg[\"Log2_speedup_over_Serial\"])\n",
    "florida_pchol_agg[\"Geommean_hdagg\"] = np.exp2(florida_pchol_agg[\"Log2_speedup_over_HDagg\"])\n",
    "florida_pchol_agg[\"Geommean_spmp\"] = np.exp2(florida_pchol_agg[\"Log2_speedup_over_SpMP\"])\n",
    "florida_pchol_agg[\"Geommean_supersteps_relative_to_Wavefront\"] = 1 / np.exp2(florida_pchol_agg[\"Log2_supersteps_relative_to_Wavefront\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "#####  The output of the following cells corresponds to Tables 7.1 & 7.2 \n",
    "###########################################################\n",
    "\n",
    "\n",
    "florida_agg[[\"Geommean_serial\", \"Geommean_hdagg\", \"Geommean_spmp\", \"Geommean_supersteps_relative_to_Wavefront\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "florida_metis_agg[[\"Geommean_serial\", \"Geommean_hdagg\", \"Geommean_spmp\", \"Geommean_supersteps_relative_to_Wavefront\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "florida_pchol_agg[[\"Geommean_serial\", \"Geommean_hdagg\", \"Geommean_spmp\", \"Geommean_supersteps_relative_to_Wavefront\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "er_agg[[\"Geommean_serial\", \"Geommean_hdagg\", \"Geommean_spmp\", \"Geommean_supersteps_relative_to_Wavefront\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_agg[[\"Geommean_serial\",\"Geommean_hdagg\", \"Geommean_spmp\", \"Geommean_supersteps_relative_to_Wavefront\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "#####  The output of this cell corresponds to Table 7.6  \n",
    "###########################################################\n",
    "\n",
    "florida_agg[[\"Profitability\" , \"q25\", \"median_profitability\", \"q75\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "#####  The output of this cell corresponds to Figure 1.2\n",
    "###########################################################\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "for name, group in florida_FLOPS.groupby(\"Processors\"):\n",
    "    plt.figure(figsize=(6,4))\n",
    "    \n",
    "    ax = sns.violinplot(palette=sns.color_palette(\"husl\", 6)[4:5], x=\"Algorithm\", y=\"Log2_speedup_over_Serial\", order=[\"SMGreedyBspGrowLocalAutoCoresParallel\", \"SpMP\", \"HDAGG_BIN\" ], inner=\"quart\", data=group[group[\"Algorithm\"].isin([\"HDAGG_BIN\", \"SpMP\", \"SMGreedyBspGrowLocalAutoCoresParallel\"])]) \n",
    "\n",
    "    plt.xlabel(\"\", fontsize=0, labelpad=10)\n",
    "    \n",
    "    #Warning: Labels are not guaranteed to be in the correct order\n",
    "    plt.xticks(ticks=[0,1,2], labels=[\"GrowLocal\", \"SpMP\" ,\"HDagg\"], fontsize=14)\n",
    "    plt.yticks(fontsize=14, ticks=[-2, -1, 0, 1 , 2 , 3 , 4, 5], labels=[\"0.25\", \"0.5\", \"1\", \"2\", \"4\", \"8\", \"16\", \"32\"])\n",
    "    \n",
    "    plt.ylabel(\"Speed-up over Serial\", fontsize=14)\n",
    "    plt.savefig(\"intro_plot_violin.eps\", bbox_inches=\"tight\", transparent=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schedule compute time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Log speed-ups of schedule computation time over HDagg\n",
    "geom_mean_FLOPS_df[[\"Processors\", \"Algorithm\", \"Log2_Schedule_Compute_time_speedup_over_HDagg\"]].groupby([\"Processors\",\"Algorithm\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scheduling Scatterplot\n",
    "\n",
    "best_linear_fit_log_normalised = True\n",
    "\n",
    "alg_filter_sched_time_scatter = [\"SMFunOriGrowlv2\", \"SMGreedyBspGrowLocalAutoCoresParallel\"]\n",
    "\n",
    "reg = dict()\n",
    "\n",
    "if best_linear_fit_log_normalised:\n",
    "    for alg in alg_filter_sched_time_scatter:\n",
    "        if alg not in geom_mean_FLOPS_df[\"Algorithm\"].unique():\n",
    "            continue\n",
    "        tmp_df = geom_mean_FLOPS_df[ geom_mean_FLOPS_df[\"Algorithm\"] == alg ]\n",
    "        X = tmp_df[\"NNZ\"].to_numpy()\n",
    "        y = tmp_df[\"Schedule_Compute_time\"].to_numpy()\n",
    "        \n",
    "        err = np.log2(y) - np.log2(X)\n",
    "        reg[alg] = np.mean(err)\n",
    "        \n",
    "else:\n",
    "    for alg in alg_filter_sched_time_scatter:\n",
    "        if alg not in geom_mean_FLOPS_df[\"Algorithm\"].unique():\n",
    "            continue\n",
    "        tmp_df = geom_mean_FLOPS_df[ geom_mean_FLOPS_df[\"Algorithm\"] == alg ]\n",
    "        X = tmp_df[[\"NNZ\"]].to_numpy()\n",
    "        y = tmp_df[\"Schedule_Compute_time\"].to_numpy()\n",
    "\n",
    "        X = X.reshape(-1, 1)\n",
    "        y = y.reshape(-1, 1)\n",
    "\n",
    "        reg[alg] = LinearRegression(fit_intercept=False)\n",
    "        reg[alg].fit(X, y)\n",
    "    \n",
    "\n",
    "g = sns.scatterplot(data=geom_mean_FLOPS_df[geom_mean_FLOPS_df[\"Algorithm\"].isin(alg_filter_sched_time_scatter)],\n",
    "            x=\"NNZ\", y=\"Schedule_Compute_time\", hue=\"Algorithm\", style=\"Algorithm\")\n",
    "if best_linear_fit_log_normalised:\n",
    "    g.set(yscale=\"log\")\n",
    "    g.set(xscale=\"log\")\n",
    "plt.xlabel(\"Number of non-zeros\")\n",
    "plt.ylabel(\"Schedule compute time [ms]\")\n",
    "plt.legend(title=\"Algorithm\")\n",
    "leg = g.axes.get_legend()\n",
    "new_labels = ['Funnel+GL', 'GrowLocal']\n",
    "for t, l in zip(leg.texts, new_labels):\n",
    "    t.set_text(l)\n",
    "sns.move_legend(g, \"lower right\")\n",
    "\n",
    "\n",
    "if best_linear_fit_log_normalised:\n",
    "    arr = np.linspace(min(geom_mean_FLOPS_df[\"NNZ\"].unique()), max(geom_mean_FLOPS_df[\"NNZ\"].unique()), 10001)\n",
    "    arr = arr.reshape(-1, 1)\n",
    "\n",
    "    for alg in alg_filter_sched_time_scatter:\n",
    "        if alg not in geom_mean_FLOPS_df[\"Algorithm\"].unique():\n",
    "            continue\n",
    "        plt.plot(arr, arr * np.exp2(reg[alg]))\n",
    "else:\n",
    "    arr = np.linspace(min(geom_mean_FLOPS_df[\"NNZ\"].unique()), max(geom_mean_FLOPS_df[\"NNZ\"].unique()), 10001)\n",
    "    arr = arr.reshape(-1, 1)\n",
    "\n",
    "    for alg in alg_filter_sched_time_scatter:\n",
    "        if alg not in geom_mean_FLOPS_df[\"Algorithm\"].unique():\n",
    "            continue\n",
    "        plt.plot(arr, reg[alg].predict(arr))        \n",
    "\n",
    "plt.savefig(\"schedule_compute_time_1_thread.eps\", bbox_inches=\"tight\", transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_dict = {'HDAGG_BIN': \"HDagg\",\n",
    "            'Serial': \"Serial\",\n",
    "            'SpMP': \"SpMP\",\n",
    "            'SMFunOriGrowlv2': \"Funnel+GL\",\n",
    "            'SMGreedyBspGrowLocalAutoCoresParallel': \"GrowLocal\"\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpTrSV_df_florida = SpTrSV_df_filtered[ SpTrSV_df_filtered[\"Graph\"].isin(florida_graphs) ]\n",
    "smallest_runtime_df = SpTrSV_df_florida.groupby(\"Graph\").min()\n",
    "total_runs_df = SpTrSV_df_florida.groupby(\"Algorithm\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_threshold = 5.0\n",
    "granularity = 513\n",
    "\n",
    "performance_df = pd.DataFrame()\n",
    "\n",
    "for alg, df in SpTrSV_df_florida[[\"Graph\", \"Algorithm\", \"SpTrSV_Runtime\"]].groupby(\"Algorithm\"):\n",
    "    #skipping algorithms\n",
    "    if alg in [\"Serial\", \"Wavefront\"]:\n",
    "        continue\n",
    "    for threshhold in np.linspace(1.0, max_threshold, num = granularity):\n",
    "        count = 0\n",
    "        for graph_name, runs_df in df.groupby(\"Graph\"):\n",
    "            number_runs_smaller_than_thresh = len( runs_df[runs_df[\"SpTrSV_Runtime\"] <= threshhold * smallest_runtime_df.at[graph_name, \"SpTrSV_Runtime\"]].index)\n",
    "            count += number_runs_smaller_than_thresh\n",
    "        performance_df.loc[threshhold, alg_dict[alg]] = count / total_runs_df.at[alg, \"Graph\"]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "#####  The output of this cell corresponds to Figure 7.1\n",
    "###########################################################\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "perf_plot = sns.lineplot(data=performance_df, palette=sns.color_palette(\"husl\", 6))\n",
    "perf_plot.set_ylim(0.0, 1.0)\n",
    "perf_plot.set_xlim(1.0, max_threshold)\n",
    "sns.move_legend(perf_plot, \"lower right\")\n",
    "plt.savefig(\"performance_plot_florida.eps\", bbox_inches=\"tight\", transparent=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
