{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python version: 3.11.0\n",
    "# matplotlib==3.10.0\n",
    "# pandas==2.2.3\n",
    "# numpy==2.2.1\n",
    "# scipy==1.15.0\n",
    "# seaborn==0.13.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph statistics files\n",
    "graph_stat_files = {\"./graph_hdagg_metis.txt\", \"./graph_florida_stats.txt\", \"./graph_erdos_renyi_stats.txt\", \"./graph_band_stats.txt\", \"./graph_iChol_stats.txt\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading files into pandas dataframe\n",
    "graph_df = pd.concat( [pd.read_csv(file) for file in graph_stat_files ], ignore_index=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping duplicates\n",
    "graph_df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing index to Graph\n",
    "graph_df = graph_df.set_index(\"Graph\", drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding double precision floating point operations to the dataframe\n",
    "graph_df[\"FLOP_double_precision\"] = 2 * graph_df[\"Edges\"] + graph_df[\"Vertices\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding number of non-zeroes to the dataframe\n",
    "graph_df[\"Number_of_non-zeroes\"] = graph_df[\"Edges\"] + graph_df[\"Vertices\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph filter templates\n",
    "\n",
    "# All graphs\n",
    "all_graphs = set(graph_df.index)\n",
    "\n",
    "# Erdos-Renyi graphs\n",
    "erdos_renyi_graphs = set( [g for g in all_graphs if g[:5] == \"Erdos\" ] )\n",
    "\n",
    "# Random Bandwidth graphs\n",
    "random_band_graphs = set( [g for g in all_graphs if g[:10] == \"RandomBand\" ] )\n",
    "\n",
    "# Florida post Eigen Cholesky graphs\n",
    "cholesky_graphs = set( [g for g in all_graphs if g[-9:] == \"_postChol\" ] )\n",
    "florida_metis_graphs = set( [g for g in all_graphs if g[-6:] == \"_metis\" ] )\n",
    "\n",
    "\n",
    "# Florida graphs\n",
    "florida_graphs = set( [g for g in all_graphs if g not in random_band_graphs and g not in erdos_renyi_graphs and g[:4] != \"inst\"  and g not in florida_metis_graphs and g not in cholesky_graphs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting graph filters for subsequent SpTrSV data analysis\n",
    "# graph_subset = all_graphs \n",
    "# graph_subset = erdos_renyi_graphs\n",
    "# graph_subset = random_band_graphs\n",
    "# graph_subset = cholesky_graphs\n",
    "graph_subset = florida_graphs\n",
    "# graph_subset = florida_metis_graphs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpTrSV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder location\n",
    "folder_location = \"./SpTrSV_Data/SC_threads_experiments/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing all files in folder_location\n",
    "data_files = set([file for file in os.listdir(folder_location)])\n",
    "data_files = [file for file in data_files if file[:3] != \"log\"]\n",
    "data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying Datatypes\n",
    "data_type_dic = {\n",
    "    \"Graph\":                            \"object\",\n",
    "    \"Machine\":                          \"object\",\n",
    "    \"Algorithm\":                        \"object\",\n",
    "    \"Permutation\":                      \"object\",\n",
    "    \"SpTrSV_Runtime\":                  \"float64\",\n",
    "    \"Work_Cost\":                         \"int64\",\n",
    "    \"Base_Comm_Cost\":                    \"int64\",\n",
    "    \"Supersteps\":                        \"int64\",\n",
    "    \"_Base_Buffered_Sending\":            \"int64\",\n",
    "    \"Base_CostsTotalCommunication\":    \"float64\",\n",
    "    \"Schedule_Compute_time\":             \"int64\",\n",
    "    \"Processors\":                        \"int64\",\n",
    "    \"BSP_g\":                             \"int64\",\n",
    "    \"BSP_l\":                             \"int64\",\n",
    "    \"Scheduling_Threads\":                \"int64\",\n",
    "}\n",
    "\n",
    "data_default_na_val_dic = {\n",
    "    \"Graph\":                              \"\",\n",
    "    \"Machine\":                            \"\",\n",
    "    \"Algorithm\":                          \"\",\n",
    "    \"Permutation\":                        \"\",\n",
    "    \"SpTrSV_Runtime\":                  \"0.0\",\n",
    "    \"Work_Cost\":                         \"0\",\n",
    "    \"Base_Comm_Cost\":                    \"0\",\n",
    "    \"Supersteps\":                        \"1\",\n",
    "    \"_Base_Buffered_Sending\":            \"0\",\n",
    "    \"Base_CostsTotalCommunication\":    \"0.0\",\n",
    "    \"Schedule_Compute_time\":             \"1\",\n",
    "    \"Processors\":                        \"0\",\n",
    "    \"BSP_g\":                             \"0\",\n",
    "    \"BSP_l\":                             \"0\",\n",
    "    \"Scheduling_Threads\":                \"1\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading files into pandas dataframe\n",
    "SpTrSV_df = pd.concat( [pd.read_csv( folder_location + file) for file in data_files], ignore_index=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Deleting folder structure from 'Graph' column\n",
    "SpTrSV_df[\"Graph\"] = SpTrSV_df[\"Graph\"].str.split(\"/\").str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding BSP parameters to the dataframe\n",
    "SpTrSV_df[[\"Processors\", \"BSP_g\", \"BSP_l\"]] = SpTrSV_df[\"Machine\"].str.split(\"_\", n=2, expand=True).reindex(range(3), axis=1)\n",
    "SpTrSV_df[\"Processors\"] = SpTrSV_df[\"Processors\"].astype(\"object\").str.slice(start=1).astype(\"int64\", errors=\"ignore\")\n",
    "SpTrSV_df[\"BSP_g\"] = SpTrSV_df[\"BSP_g\"].astype(\"object\").str.slice(start=1).astype(\"int64\", errors=\"ignore\")\n",
    "SpTrSV_df[\"BSP_l\"] = SpTrSV_df[\"BSP_l\"].astype(\"object\").str.slice(start=1).astype(\"int64\", errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casting to correct Datatypes\n",
    "for key, val in data_type_dic.items():\n",
    "    SpTrSV_df[key] = SpTrSV_df[key].fillna(data_default_na_val_dic[key]).astype(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute giga double precision floating point operations, denoted by GFP64\n",
    "def compute_GFP64(time, graph, df = graph_df):\n",
    "    flop = df.at[graph ,\"FLOP_double_precision\"]\n",
    "    return (flop / time) / 1000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding giga double precision floating point operations, denoted by GFP64, to the dataframe\n",
    "SpTrSV_df[\"GFP64/s\"] = SpTrSV_df[[\"Graph\", \"SpTrSV_Runtime\"]].apply(lambda x: compute_GFP64(x[\"SpTrSV_Runtime\"], x[\"Graph\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set schedule compute time at least 1ms\n",
    "SpTrSV_df[\"Schedule_Compute_time\"] = SpTrSV_df[\"Schedule_Compute_time\"].replace(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data sorting\n",
    "SpTrSV_df.sort_values([ \"Graph\", \"Algorithm\" ], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters (incl. Algorithm, Processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting algorithm filter\n",
    "alg_filter_set = set(SpTrSV_df[\"Algorithm\"].unique())\n",
    "alg_filter_set = set([\"SMGreedyBspGrowLocalAutoCoresParallel\"])\n",
    "                   \n",
    "\n",
    "# Must always contain Serial\n",
    "alg_filter_set.add(\"Serial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting processor filter\n",
    "proc_filter = SpTrSV_df[\"Processors\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying algorithm filter\n",
    "SpTrSV_df_filtered = SpTrSV_df[ SpTrSV_df[\"Algorithm\"].isin(alg_filter_set) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying graph filter\n",
    "SpTrSV_df_filtered = SpTrSV_df_filtered[ SpTrSV_df_filtered[\"Graph\"].isin(graph_subset) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying processor filter\n",
    "SpTrSV_df_filtered = SpTrSV_df_filtered[ SpTrSV_df_filtered[\"Processors\"].isin(proc_filter) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up new pandas dataframe with geometric mean of GFP64 and speed-up over serial execution\n",
    "geom_mean_FLOPS_df = pd.DataFrame(columns=[\"Processors\", \"Graphs\", \"Algorithm\", \"GFP64/s\", \"Speedup_over_Serial\", \"Profitability\", \"Schedule_Compute_time\", \"Supersteps_relative_to_Wavefront\", \"Scheduling_Threads\", \"Multi_Thread_FLOP_decrease\", \"Multi_Thread_sched_time_speedup\", \"Multi_Thread_superstep_increase\"])\n",
    "for name, group in SpTrSV_df_filtered.groupby([\"Processors\", \"Graph\"]):\n",
    "    serial_flops = np.exp( np.log(group[ group[\"Algorithm\"] == \"Serial\" ][\"GFP64/s\"]).mean() )\n",
    "    serial_run_time_am = group[group[\"Algorithm\"] == \"Serial\" ][\"SpTrSV_Runtime\"].mean()    \n",
    "   \n",
    "    for alg, alg_group in group.groupby(\"Algorithm\"):\n",
    "        alg_1sched_thread_flops = np.exp( np.log(alg_group[ alg_group[\"Scheduling_Threads\"] == 1 ][\"GFP64/s\"]).mean())\n",
    "        alg_1sched_thread_schedule_compute_time = alg_group[ alg_group[\"Scheduling_Threads\"] == 1 ][\"Schedule_Compute_time\"].mean()\n",
    "        alg_1sched_thread_supersteps = alg_group[ alg_group[\"Scheduling_Threads\"] == 1 ][\"Supersteps\"].mean()\n",
    "        \n",
    "        for sched_thr, thr_group in alg_group.groupby(\"Scheduling_Threads\"):\n",
    "            flops = np.exp( np.log(thr_group[\"GFP64/s\"]).mean())\n",
    "            run_time_am = thr_group[\"SpTrSV_Runtime\"].mean()\n",
    "            alg_schedule_compute_time = thr_group[\"Schedule_Compute_time\"].mean()\n",
    "            alg_supersteps = thr_group[\"Supersteps\"].mean()\n",
    "            wavefront_supersteps = graph_df.at[name[1], \"Longest_Path\"]\n",
    "\n",
    "            profitable = 0\n",
    "            if (alg == \"Serial\"):\n",
    "                profitable = 0\n",
    "            else:\n",
    "                # conversion of alg_schedule_compute_time to s from ms\n",
    "                profitable = (alg_schedule_compute_time / 1000.0) / (serial_run_time_am - run_time_am)\n",
    "                if (profitable < 0.0):\n",
    "                    profitable = np.inf\n",
    "\n",
    "            temp_df = pd.DataFrame([[name[0],      name[1],  alg,         flops,     flops/serial_flops,    profitable,      alg_schedule_compute_time, alg_supersteps/wavefront_supersteps, sched_thr,            flops/alg_1sched_thread_flops, alg_1sched_thread_schedule_compute_time/alg_schedule_compute_time, alg_supersteps/alg_1sched_thread_supersteps]],\n",
    "                            columns=[\"Processors\", \"Graphs\", \"Algorithm\", \"GFP64/s\", \"Speedup_over_Serial\", \"Profitability\", \"Schedule_Compute_time\",   \"Supersteps_relative_to_Wavefront\",  \"Scheduling_Threads\", \"Multi_Thread_FLOP_decrease\",  \"Multi_Thread_sched_time_speedup\",                                 \"Multi_Thread_superstep_increase\"] )\n",
    "            geom_mean_FLOPS_df = pd.concat([geom_mean_FLOPS_df, temp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding logarithm of speed-up over serial\n",
    "geom_mean_FLOPS_df[\"Log2_speedup_over_Serial\"] = np.log2( geom_mean_FLOPS_df[\"Speedup_over_Serial\"] )\n",
    "geom_mean_FLOPS_df[\"Log2_supersteps_relative_to_Wavefront\"] = np.log2( geom_mean_FLOPS_df[\"Supersteps_relative_to_Wavefront\"] )\n",
    "geom_mean_FLOPS_df[\"Log2_Multi_Thread_FLOP_decrease\"] = np.log2( geom_mean_FLOPS_df[\"Multi_Thread_FLOP_decrease\"] )\n",
    "geom_mean_FLOPS_df[\"Log2_Multi_Thread_sched_time_speedup\"] = np.log2( geom_mean_FLOPS_df[\"Multi_Thread_sched_time_speedup\"] )\n",
    "geom_mean_FLOPS_df[\"Log2_Multi_Thread_superstep_increase\"] = np.log2( geom_mean_FLOPS_df[\"Multi_Thread_superstep_increase\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding number of non-zeros\n",
    "geom_mean_FLOPS_df[\"NNZ\"] = geom_mean_FLOPS_df[\"Graphs\"].apply(lambda x: graph_df.at[x,\"Number_of_non-zeroes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GFP64/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Log speed-ups over Serial\n",
    "\n",
    "agg_df = geom_mean_FLOPS_df[[\"Processors\", \"Algorithm\",\"Log2_speedup_over_Serial\", \"Profitability\", \"Schedule_Compute_time\", \"Log2_supersteps_relative_to_Wavefront\", \"Scheduling_Threads\", \"Log2_Multi_Thread_FLOP_decrease\", \"Log2_Multi_Thread_sched_time_speedup\", \"Log2_Multi_Thread_superstep_increase\"]].groupby([\"Processors\", \"Algorithm\", \"Scheduling_Threads\"]).mean()\n",
    "agg_df[\"Geommean_serial\"] = np.exp2(agg_df[\"Log2_speedup_over_Serial\"])\n",
    "agg_df[\"Geommean_supersteps_relative_to_Wavefront\"] = 1 / np.exp2(agg_df[\"Log2_supersteps_relative_to_Wavefront\"])\n",
    "agg_df[\"GM_MulThr_FLOP_decrease\"] = np.exp2(agg_df[\"Log2_Multi_Thread_FLOP_decrease\"])\n",
    "agg_df[\"GM_MulThr_sched_time_speedup\"] = np.exp2(agg_df[\"Log2_Multi_Thread_sched_time_speedup\"])\n",
    "agg_df[\"GM_MulThr_superstep_increase\"] = np.exp2(agg_df[\"Log2_Multi_Thread_superstep_increase\"])\n",
    "\n",
    "agg_df[\"median_profitability\"] = geom_mean_FLOPS_df[[\"Processors\", \"Algorithm\", \"Profitability\", \"Scheduling_Threads\"]].groupby([\"Processors\", \"Algorithm\", \"Scheduling_Threads\"]).median()\n",
    "agg_df[\"q25\"] = geom_mean_FLOPS_df[[\"Processors\", \"Algorithm\", \"Profitability\", \"Scheduling_Threads\"]].groupby([\"Processors\", \"Algorithm\", \"Scheduling_Threads\"]).quantile(0.25)\n",
    "agg_df[\"q75\"] = geom_mean_FLOPS_df[[\"Processors\", \"Algorithm\", \"Profitability\", \"Scheduling_Threads\"]].groupby([\"Processors\", \"Algorithm\", \"Scheduling_Threads\"]).quantile(0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "#####  The output of the following cells corresponds to Table 7.7 \n",
    "###########################################################\n",
    "\n",
    "agg_df[[\"Geommean_serial\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df[[\"Profitability\" , \"q25\", \"median_profitability\", \"q75\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df[[\"GM_MulThr_sched_time_speedup\", \"GM_MulThr_FLOP_decrease\", \"GM_MulThr_superstep_increase\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
